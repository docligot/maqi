{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.ops import cascaded_union\n",
    "import geopandas as gpd\n",
    "\n",
    "\n",
    "from sentinelhub import FisRequest, BBox, Geometry, CRS, WcsRequest, CustomUrlParam, \\\n",
    "    DataCollection, HistogramType, bbox_to_dimensions\n",
    "from sentinelhub.time_utils import iso_to_datetime\n",
    "from sentinelhub import DataCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentinel hub configurations\n",
    "from sentinelhub import SHConfig\n",
    "\n",
    "\n",
    "INSTANCE_ID = ''  # In case you put instance ID into configuration file you can leave this unchanged\n",
    "\n",
    "if INSTANCE_ID:\n",
    "    config = SHConfig()\n",
    "    config.instance_id = INSTANCE_ID\n",
    "else:\n",
    "    config = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fis_data_to_dataframe(fis_data):\n",
    "    \"\"\" Creates a DataFrame from list of FIS responses\n",
    "    \"\"\"\n",
    "    COLUMNS = ['channel', 'date', 'min', 'max', 'mean', 'stDev']\n",
    "    data = []\n",
    "\n",
    "    for fis_response in fis_data:\n",
    "        for channel, channel_stats in fis_response.items():\n",
    "            for stat in channel_stats:\n",
    "                row = [int(channel[1:]), iso_to_datetime(stat['date'])]\n",
    "\n",
    "                for column in COLUMNS[2:]:\n",
    "                    row.append(stat['basicStats'][column])\n",
    "\n",
    "                data.append(row)\n",
    "\n",
    "    return pd.DataFrame(data, columns=COLUMNS).sort_values(['channel', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to clean df ready for analysis\n",
    "def clean_df (json_stats):\n",
    "    raw_df_stats = fis_data_to_dataframe(json_stats).reset_index(drop=True)\n",
    "    index_df = raw_df_stats[raw_df_stats.channel ==0]\n",
    "    cloud_df = raw_df_stats[raw_df_stats.channel ==1]\n",
    "    cloud_df = cloud_df.drop(['channel'], axis=1).add_suffix('_clm')\n",
    "    merged_df = pd.merge(index_df, cloud_df, left_on ='date', right_on = 'date_clm', how='outer')\n",
    "    clean_merged_df = merged_df.drop(['channel', 'date_clm'], axis=1)\n",
    "    return clean_merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read single_region geojson in geopandas\n",
    "single_region = gpd.read_file(\"ADD YOUR AREA OF INTEREST (.shp or .geojson ) HERE\")\n",
    "single_region_geometry = Geometry(single_region.geometry.values[0], crs=CRS.WGS84)\n",
    "\n",
    "# for the next interation use cascaded_union to combine \n",
    "# all polygons in the multipolygon by using all the external point as their boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize request to obtain basic stats and histogram values\n",
    "# warning if the timeline is to long there if error timeout at their server\n",
    "single_region_geometry_n = FisRequest(\n",
    "    data_collection=DataCollection.SENTINEL5P,\n",
    "    layer='NO2',\n",
    "    geometry_list=[single_region_geometry],\n",
    "    time=('2020-06-20', '2020-06-22'),\n",
    "    resolution='1000m',\n",
    "    config=config\n",
    ")\n",
    "\n",
    "single_region_geometry_stats_n = single_region_geometry_n.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# request will return json output\n",
    "single_region_geometry_stats_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_region_stats_clean = clean_df(single_region_geometry_stats_n)\n",
    "single_region_stats_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_region_stats_clean.to_csv('regional_no2_results/ARMM_region_stats_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
